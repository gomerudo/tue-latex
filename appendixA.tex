\section*{Appendix A}\label{app:preliminaries}
% \section{Preliminaries}

To aid with the presentation of our work, we develop some concepts of Neural Architecture Search (NAS), which are highly inspired in the survey by~\cite{NASsurvey}. Although for the ones familiar with NAS they may seem redundant, we believe that our definitions help to think of NAS as a whole framework that can be studied from different endpoints. We start by defining NAS and later we elaborate more on each of its components.

\begin{definition}[Neural Architecture Search]
\label{def:nas}
Let $A^*$ be the set of all existing neural architectures, $D$ a dataset, $R: A \times D \mapsto \mathbb{R}$ a function measuring the performance of any architecture $A_i \in A^*$ on $D$. The Neural Architecture Search (NAS) problem is modeled as finding a search function $L: D \mapsto A$ maximizing $R$ (w.l.o.g. minimizing).
\end{definition}

\subsection*{The Neural Architecture Search elements}

On purpose, Definition~\ref{def:nas} is left open with respect to the choice of the function $R$, the formal definition of the dataset $D$, the properties of the function $L$, and the characteristics of the architectures in the set $A^*$. In particular, for some problem $\theta_D$ it is desirable to delimit NAS by defining a function $L_\theta$, a set $A_\theta \subset A*$ and any $R$. The later elements are known as the \textit{search space}, the \textit{search strategy} and the \textit{performance estimation strategy}, respectively, which we describe next.

\subsubsection*{The Search Space}

As an abstract concept, the \textit{search space} is the set $A^*$ of all existing architectures. This set is in principle infinite, since no restrictions are imposed on the depth of the networks nor the connections between layers and therefore, it is desirable to define it in terms of the properties of the architectures populating it.

Concretely, let $\theta_{D}$ be a classification problem for a dataset $D$. The search space generator $S_{\theta}$ is a function defined as follow:

% Some other restrictions that can be placed are the \textit{domain of the problem} being addressed and the \textit{subfamily of architectures} to consider. Take for example a traditional
% Convolutional Neural Network (CNN) such as the LeNet \cite{Y1998}, that we can think of as a set of stacked layers where the elements can be of type \textit{convolution}, \textit{pooling}, \textit{normalization} or \textit{fully-connected}.

% Independently of the restrictions aforementioned, from a programmatic perspective, the search space is not supposed to be indicated as a \textit{hard-coded} collection of well-defined architectures and instead, it is preferred to define it in terms of a) the elements that can be part of those architectures and b) the way inputs-outputs of these elements can be linked. Hence, the search space could be defined as \textit{all possible architectures produced using a certain depth and a set of allowed elements that can be linked using certain constraints}. To model this, we introduce equation \ref{eq:search_space} since, in practice, it is useful to ``replace" $A_\theta$ with this triplet.

\begin{equation}\label{eq:search_space}
S_\theta: (d, E, C) \mapsto \{a_i \in A^*\}
\end{equation}
where:

\begin{itemize}
    % \setlength\itemsep{-0.5em}
    \item[] $d:$ The maximum depth allowed in the architectures.
    \item[] $E:$ The set of elements allowed at any layer in the architecture.
    \item[] $C:$ The constraints modeling the allowed connections between layers.
\end{itemize}

The role of the generator $S_{\theta}$ is to take a triplet of values to restrict the search space to a finite number of architectures. Once more, the formal definition of some elements is left open: the sets $E$ and $C$. For the first, the elements allowed can be modeled in two different ways: as atomic elements (e.g. a convolution, a pooling, a regularizer) or as a group of elements or \textit{cells} (e.g. a convolution followed by a pooling and a regularizer). For the set $C$, the constraints can include the branching properties (e.g. chain-structured, multi-branching, etc.), the way predecessors are chosen, valid and invalid connections, etc.
%The values of this triplet $E$ using atomic elements \cite{Zoph2017} \cite{Baker2016} (e.g. one convolutional layer) or as a group of elements or \textit{cells} \cite{Zhong} (e.g. a convolutional layer linked to a pooling layer). The latter idea is depicted in Figure \ref{fig:nas_graphs}.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.6\textwidth]{images/nas_graph.png}
%     \caption{Different abstractions of the search space. From left to right, the first two figures represent an architecture modeled by atomic elements (different colors represent different type of elements). The last figure represents an architecture modeled by \textit{cells}.}
%     \label{fig:nas_graphs}
% \end{figure}

\subsubsection*{The Performance Estimation Strategy}

The function $R$ in Definition~\ref{def:nas} is known as the \textit{performance estimation strategy}. This function takes an architecture $a_i \in A_\theta$ and a dataset $D$ and returns a value $r \in \mathbb{R}$ measuring the performance of the network on the task $\theta_D$. For this, the traditional \textit{validation} score can be used for this purpose, however, it is a very expensive procedure in NAS, since many architectures are required for training and evaluation. To overcome this issue, different methods can be used, such as early stop, learning curves extrapolation, etc.

\subsubsection*{The Search Strategy}

The purpose of a \textit{search strategy} is to output an architecture $a_{opt} \in A_\theta$ that gets the best possible performance for the task $\theta_D$ when evaluated with the function $R$. Given $\theta_D$ we define the search strategy as an algorithm $L_\theta$ that accomplishes this goal or at least can find the best possible $a_{best} \in A_\theta$. Ideally, one would like to have a reliable, deterministic, and computationally reasonable $L_\theta$, nevertheless no research has found this feasible and thus one needs to settle down with designing and feed the algorithm with sufficient prior-knowledge of how to explore the space populated by the function $S_\theta$, so that $a_{best}$ can be spotted.


% \label{app:theorem}

% Note: in this sample, the section number is hard-coded in. Following
% proper LaTeX conventions, it should properly be coded as a reference:

%In this appendix we prove the following theorem from
%Section~\ref{sec:textree-generalization}:

% In this appendix we prove the following theorem from
% Section~6.2:

% \noindent
% {\bf Theorem} {\it Let $u,v,w$ be discrete variables such that $v, w$ do
% not co-occur with $u$ (i.e., $u\neq0\;\Rightarrow \;v=w=0$ in a given
% dataset $\dataset$). Let $N_{v0},N_{w0}$ be the number of data points for
% which $v=0, w=0$ respectively, and let $I_{uv},I_{uw}$ be the
% respective empirical mutual information values based on the sample
% $\dataset$. Then
% \[
% 	N_{v0} \;>\; N_{w0}\;\;\Rightarrow\;\;I_{uv} \;\leq\;I_{uw}
% \]
% with equality only if $u$ is identically 0.} \hfill\BlackBox

% \noindent
% {\bf Proof}. We use the notation:
% \[
% P_v(i) \;=\;\frac{N_v^i}{N},\;\;\;i \neq 0;\;\;\;
% P_{v0}\;\equiv\;P_v(0)\; = \;1 - \sum_{i\neq 0}P_v(i).
% \]
% These values represent the (empirical) probabilities of $v$
% taking value $i\neq 0$ and 0 respectively.  Entropies will be denoted
% by $H$. We aim to show that $\fracpartial{I_{uv}}{P_{v0}} < 0$....\\

% {\noindent \em Remainder omitted in this sample. See http://www.jmlr.org/papers/ for full paper.}
