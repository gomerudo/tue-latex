\section{Introduction}

In recent years, neural networks achieved remarkable results in many fields, such as that of Image Classification. Crucial aspects of this success are the choice of the neural architecture and the exploitation of the hyperparameters associated to its layout, so that a certain function measuring its performance against some particular dataset of interest can be optimized. However, improving the existing architectures or coming up with novel ones are challenging, cumbersome and restricted tasks, since they rely on the designer's level of expertise and may demand computationally expensive trials. %Furthermore, state-of-the-art architectures are optimized for very specific datasets, making it non-trivial for Deep Learning practitioners to transfer them to classification tasks on new data.

In an attempt to overcome these limitations, various techniques have been explored under the name of Neural Architecture Search (NAS)~\citep{NASsurvey}. In NAS, the ultimate goal is to come up with an algorithm that can output a well-performing neural network for any arbitrary dataset, so that the dependency on human intervention can be dropped from the design process. Nevertheless, coming up with a solution of this kind is a complex labour that requires attention from different flanks, making NAS a diverse area where researchers deal with several aspects, such as the type of the networks that are considered (e.g. chain-structured networks, multi-branch networks, convolutional cells, etc.), the portion of the design that is automated (e.g. the tuning of the hyperparemeters, the connections between layers, the layout of the layers, etc.), or the strategy used to search for the best network (e.g. neuro-evolutionary algorithms, reinforcement learning, random search, etc.).

In particular, NAS via reinforcement learning has proved successful at designing Convolutional Neural Networks (CNNs) for image classification tasks. Remarkable results have been achieved by using popular policy optimization algorithms, such as \textsc{Q-learning} or \textsc{Reinforce}, to search for good chain-structured networks, multi-branch networks, and convolutional cells that can achieve state-of-the-art performance on classification tasks for the CIFAR-10 and the ImageNet datasets. Although promising and high-performing in terms of accuracy and error rate, two main downsides can still be found in these approaches: the high demand of computational resources, that can vary from tens to hundreds of GPUs running from 1 to 28 days per experiment; and the yet non-studied power of generalization of the learned policy when applied to datasets other than the one it was initially trained on.

Based on these observations, we aim to extend the current scope of NAS for CNNs via reinforcement learning by using a deep meta-reinforcement learning algorithm as the ones introduced in the works of~\citet{LtRL} and~\citet{RL2}, which we train under different environments that are datasets sampled from the meta-dataset collection assembled by~\citet{MetaDataset}. Under this framework, we can study two previously unexplored aspects in the area of Neural Architecture Search, which are a consequence of the \textit{meta-design} of the algorithm implemented: a) the performance of an architecture designed by a policy that developed its knowledge from different environments (i.e. datasets), and b) the performance of an adaptive policy %that can be re-used for a faster and yet efficient 
at designing neural architectures for datasets others than the ones it was initially trained on. Because of our computational limitations and time constraints, we do not aim to compete with state-of-the-art architectures for baseline datasets, %since this would require resources and time that are beyond our possibilities,
but to compare the performance of both the output network and the policy against their counterparts from a non-meta experiment using \textsc{DQN}, which allows us to study the benefits of our method. Our results show that \textbf{TODO: the actual results/conclusions :(}


The remaining of this report is structured as follows: in section~\ref{sec:related} the related work is studied, in section~\ref{sec:methodology} the methodology is detailed, in section~\ref{sec:results} the results are presented and finally, in section~\ref{sec:conclusions} the conclusions are set out. %Additionally we include two appendices: one presenting relevant concepts and definitions of NAS, and other describing the technical details of our software implementations and experiments.


% {\noindent \em Remainder omitted in this sample. See http://www.jmlr.org/papers/ for full paper.}


% % Manual newpage inserted to improve layout of sample file - not
% % needed in general before appendices/bibliography.